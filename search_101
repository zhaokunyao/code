####
做为一名PHP RD，
最先接触到的存储与查询系统基本上都是mysql（文件系统不算数）。
如果你一上来搞的就是redis或mongodb， 那么恭喜你，你已经击败了全国99.9%的RD, 
这是一件多么神奇的事情。

有了mysql之后，我们可以实现很多很多的业务，
特别是在小公司里面，掌握了mysql之后，简直可以横着走了。
随着公司规模的扩大，业务场景也越来越复杂，
奇葩需求也越来越多， mysql似乎有些不够给力了。
于是各种升级方案就出来了， 比如redis、mongodb、各种检索系统、推荐系统等等。

本文将着重讲解一下检索系统。
在开讲之前， 还需要先分析一下mysql的整个查询过程，看其中存在什么不足之处。

####

以下面的sql为例，innodb存储引擎：
```
SELECT * FROM tbl WHERE a='aaa' AND b > 10 AND c < 20 ORDER BY d DESC LIMIT 10
```
tbl表有一个自增主键id。
熟练掌握加索引技能的RD， 都知道应该在字段a与b， 或者字段a与c上面建一个联合的索引。

这个sql可以被分解为如下几个部分：
WHERE 部分;
ORDER BY 部分;
LIMIT 部分;
SELECT 部分;
下面分别讲解。

###
WHERE 部分

我们都知道，innodb的B+树索引的结构，如下：
[图]
每个叶子节点上除了有索引字段之外，还有id主键字段。
不止索引是长这样子， 原始数据也是以id主键为key的同样结构的树，叶子节点里面有全部的字段。
在这里，我们把原始数据称为clustered index， 把索引树称为secondary index.
clustered index只有一个，  而secondary index就会有多个，我们创建了多少个索引， 就会有多少个secondary index.

在执行WHERE操作的时候， mysql的查询优化器会选择索引 (a,b)的树 或者(a,c)的树， 
然后在树上召回符合条件的记录(只有主键字段)。
假设mysql选择使用(a, b)的secondary index进行召回， 得到了一批id.

### SELECT 部分

经过上面WHERE语句，得到了一批id, 
但它并没有完全满足我们的WHERE条件（未考虑c字段），
innodb还需要回到clustered index上，去取出这批id对应全部记录的全部字段(SELECT *)，并在c字段上做出过滤。
细节不展开讲，我也不太记得了。。。

###
ORDER BY部分

经过上面WHERE语句的过滤， 得到了一批结果集。
之后，就需要在d字段上对结果集进行排序。
具体的排序算法本文不再展开，可以参考文后的链接.

###
LIMIT 部分
对排序后的结果进行拆分。


####
mysql的不足

通过上一节对mysql查询过程的分析， 
再结合一些输入query进行检索的业务场景，
我们可以发现，在以下几点上，mysql存在不足之处：
1) 文本匹配模式较弱，只能支持=和like操作。 
2) 排序形式比较简单， 无法应对复杂的排序机制（比如同时按距离、静态分等多个字段综合排序）。
3) 在索引的使用上， B+树有它的限制， 无法同时使用abc三个字段上的联合索引。
4) 无法实现协同过滤等推荐策略。

### 
检索架构
####
PHPUI 
php user interface
通常来说，检索系统不会像mysql一样，把所有的数据字段都保存下来，
也不会像mysql一样，把前端需要的全部字段都返回回去。
完整的数据一般是保存在业务方的mysql中，然后同步必要的字段给到检索的系统中去。
检索系统就像是mysql的index一样，它只保存必须的数据， 且返回的时候，
只返回记录的id，以及部分摘要数据。

这样就减少了带宽传输，数据的同步量也会变少，数据不一致的概率也会降低。

不过，这样一来，就无法满足前端字段的需要， 所以需要一个PHP模块，根据检索返回的id，
再去存储中查询前端需要的字段，然后按照约定的接口格式，把数据吐给前端。

再有， 有时候前端，php，检索搞一些项目的时候，可能不小心埋了坑，
以后修复的时候，前端需要发版，或者检索来适配， 成本都相对较大，于是大家约定，
这些需要适配，或者需要hack，需要搞临时方案的逻辑，都由phpui层来完成。
比如这次robin南巡报的bug， 基本上都是由phpui层来适配解决的。

####
US
universal search
通常我们并不认为PHPUI是检索系统的一部分，至少 不是重要的组成部分，
而把US当作检索系统的入口。
它主要实现以下的功能：
0) 接收PHPUI的请求
1) 实现流量抽样策略，给流量打上不同的标记， 然后下游模块就可以根据流量的标记做小流量的实验。
2) 把召回结果打到日志里，以便于后期的日志分析。
3) 把数据返回给PHPUI.

####
DA
data analyse.
主要是对query进行解析。
比如这个query: 沈阳故宫， 我们人一眼看到它，立刻就能知道用户想搜索的是[沈阳市]的[故宫]景点，
怎样让机器理解这个query呢？
我们需要[提前]配置好解析模板，称为pattern:
[城市名称][景点名称]，
pattern中的每一个部分称为「槽」slot.
接下来就要让沈阳能够命中城市名称这个slot，让故宫能够命中景点名称slot，
解决的方法与pattern类似， 再配置一个词表，称为feature， 格式如下：
[城市名称]
北京
沈阳
[景点名称]
故宫
天安门

有了pattern与feature，就可以解析[已知]的query了。
至于使用什么样的数据结构与算法去匹配pattern与feature， 本文不再详述。
我厂使用的是lexparser， 基于2个trie树(pattern树与feature树)。

这时，如果有人搜索了[沈阳市故宫]， 那么就呵呵哒了， 没有命中我们配好的pattern.

解决方法有二种： 第一种是在feature文件中把“沈阳市”添加到城市名称slot中，
或者是修改一下pattern， 改为 [城市名称][w:2-10][景点名称]
中间那个slot就是通配符(2-10个字符)。

以上主要讲解的是基于模板和词表的query解析。
DA还可以对query进行一些处理：
如大小写转化、全半角转化、繁简体转化等等。

同时， DA还可以通过某些机制，识别出用户输入了错误或者不合理的query， 并把它改写成正确的query。
这类query纠错的机制，本文不再详述。

####
BS
basic search
为什么说它basic呢？ 因为它基本上是在实现sql语句中的select和where 部分，也就是在做召回与过滤。
做的都是最基础的工作， 
如果它的工作没做好，那么orderby 与 limit 就无从谈起了。
所以称之为basic search.

谈到bs，就不得不先提一下数据。
每一条数据，我们称之为一个文档(DOC)， 每个DOC有多个字段，这个都好理解。
与mysql类似， BS也有自己的存储系统，也有一个二级结构。
第一级结构类似于clustered index， 不过并非用b+树实现， 而是简单的hash， key就是doc.id。
value就是文档的各个字段。
这个结构就称为正排表。 主要用于根据id查询其余字段，看起来没啥大用哈。

第二级结构类似于secondary index， 一般来说需要建索引的字段都会有一个单独的secondary index,
secondary index称为倒排表。
index的key是字段本身，value就是doc.id和score。
但也有比较特殊的， 
如果某字段上面需要切词， 则secondary index的key就是切词之后的token了.
如果是数值形的字段需要建索引，就更加神奇了,  可以参见文后的链接。

对了， 在删除数据时，正排表就有用了， 首先根据id在正排中查到各种索引字段的值，
然后去每个索引字段的倒排里面删除倒排记录。

单字段或者单token的召回比较简单，直接在此字段/token的倒排表里查询就行了。
所以倒排表至少是一个hash + linked list的结构。 
比如  WHERE a='aaa'，则需要去a字段的倒排表里面根据hash function计算出'aaa'的入口，
然后遍历它的linked list就可以取出a='aaa'的全部doc.id.

下面再讲解一下多字段的联合查询， 这块的逻辑要感谢震海的答疑。
以a='aaa' and  b ='bbb' 为例：
首先根据hash function，计算出'aaa'的入口，然后从其linked list中取出第一个item，记为item_aaa_1，
item_aaa_1里面有该文档的id,
然后根据hash function，计算出'bbb'的入口， 并根据item_aaa_1的id字段，尝试在'bbb'的linked list中找到相同的id.
如果能够找到， 则认为item_aaa_1是符合条件的记录， 如果找不到，则认为item_aaa_1不符合查询条件，
然后从'bbb'的linked list中取出下一个item，并继续迭代此流程。
在这个迭代的过程中， 有各种停止策略，比如触发数停止、召回数停止、耗时停止。

在创建倒排表的时候， 通常会把linked list搞成有序的(score降序，id升序， 
这样可能是为了在停止时，丢弃的是score较差的doc)， 
谈到有序，你肯定想到了二分搜索，
不过在list上面没办法二分搜索的啦， 倒是有一个叫做skip list的结构，可以加速查找的过程 。
[图]

从倒排中取到id之后，就可以从正排里面获取doc本身(类似于SELECT *)。
然后可以根据doc的其它字段，或者用户坐标等等信息进行一轮打分或者过滤，
也就是实现自己独有的业务逻辑，
这一点mysql或者es都是无法做到的。


#### 
AS
advanced search
类似于sql语句中的ORDER BY 和 LIMIT的功能， 
虽然在bs里面已经进行了排序，但是在as中还可以再排一次序, 并进行分页操作。

而且， as还可以把请求分发给多个bs，或者是向同一个bs发送多个不同的请求，
然后merge bs的多个结果集， 并进行最终的排序和分页。
这一点显然mysql也是无法做到的.

其它的，比如要置顶某个doc， 或者要在某个特定位置插入一个doc， 均由as进行排序干预。

如果业务中还有一个推荐系统的话， as也可以同时给推荐系统发一个请求，
并把推荐的结果集与bs的结果集进行merge。

###
这套检索架构中存在的问题
1) 如果as下面挂了成百上千个bs， 那么as merge的过程就会非常的吃力。
2) 如果倒排中命中了太多的doc， 则称之为[倒排拉链过长」，性能直线下降。
3) 每一个bs中只维护了一种类型的数据， 这就使得join之类的操作比较难以开发和实现。

####

####

###
检索方法论

首先，应该建立一个评价体系， 对于一般的检索系统来说，
至少要考虑三个指标：
1）召回率： 有召回的搜索pv / 总的搜索pv.

2) 点击率： 搜索结果的点击pv / 有召回的搜索pv  。

3) 用户满意度（准确率）: 从线上随机抽取一定的query， 人工评测。

有了评价体系之后， 我们的目标就是全面提升这些指标。

具体怎样做呢？ 用常月姐姐的话来说，就是看日志，
看一下query为什么没有召回， 看一下是否有误召回的数据
然后就可以决定后续的工作方向了。


#####
参考
https://dev.mysql.com/doc/refman/5.7/en/innodb-index-types.html
https://dev.mysql.com/doc/refman/5.7/en/order-by-optimization.html
https://zh.wikipedia.org/wiki/%E8%B7%B3%E8%B7%83%E5%88%97%E8%A1%A8
http://www.cnblogs.com/zrhai/p/4143531.html
